# Chapter 8: Future Work

Based on the research outcomes of this thesis and the limitations analysis in the preceding chapter, future research can pursue in-depth exploration in four directions—feature learning, model architecture, learning paradigms, and application extension—to further enhance the performance and practicality of NILM technology.

In the feature learning direction, breaking through the limitations of manually designed features is the primary objective. Current conditioning features are designed based on domain expert experience; future work can explore data-driven automated feature learning methods. One approach is to introduce neural architecture search or differentiable feature selection techniques to automatically identify the most discriminative feature combinations from a broader set of electrical feature candidates, letting algorithms rather than manual effort determine the optimal feature space; another approach is to explore end-to-end conditioning feature learning, using auxiliary network branches to learn optimal modulation signals directly from raw power sequences, completely eliminating dependence on explicit feature engineering. Regarding feature richness, high-frequency electrical signals can be introduced as supplementary information sources: voltage and current waveforms contain rich harmonic features, power factor and apparent power can distinguish different types of electrical loads, and startup transient features are particularly effective for identifying motor-type devices; incorporating this information may significantly improve discrimination capability between similar-power devices. Additionally, deep utilization of temporal context information can be explored: user schedules, device usage time preferences, and weekday versus weekend differences contain valuable prior knowledge; organically combining this context information with power features may bring further improvements in disaggregation accuracy.

In the model architecture direction, balancing efficiency and performance is the core issue. To meet edge deployment requirements, multiple model compression techniques can be explored: knowledge distillation methods can transfer CondiNILMformer's knowledge to lightweight student networks, maintaining disaggregation performance as much as possible while significantly reducing computational overhead; model quantization techniques can convert floating-point parameters to low-bit fixed-point representations, reducing storage requirements and accelerating inference; structured pruning can remove redundant network connections and channels while preserving model functionality. At the fundamental architecture level, state space models (such as Mamba, S4, etc.) that have emerged in recent years demonstrate efficiency advantages over Transformers in long sequence modeling tasks; their linear complexity characteristics are particularly suitable for handling long time windows in NILM, meriting systematic comparative study on load disaggregation tasks. For the difficult scenario of simultaneous multi-device activation, graph neural network-based device relationship modeling methods can be explored, explicitly encoding mutual exclusion relationships between devices (such as kettle and dishwasher typically not used simultaneously) and co-occurrence relationships (such as TV and set-top box typically turning on together) into the model, leveraging these structured priors to improve disaggregation accuracy. Hybrid architectures are also worth exploring, combining the local feature extraction capability of convolutional networks, the sequence modeling capability of recurrent networks, and the global dependency capture capability of attention mechanisms to design task-specific optimal architecture combinations.

In the learning paradigm direction, the transition from static offline training to dynamic adaptive learning is an important trend. Current methods fix model parameters after training completion, unable to adapt to environmental changes after deployment. Incremental learning mechanisms enable models to continuously learn new electricity usage patterns without forgetting existing knowledge, adapting to gradual user behavior changes and new device integration; federated learning frameworks allow model updates using distributed data while protecting user privacy, with multiple households' data collaboratively contributing to model improvement without centralized collection of raw data. Domain adaptation techniques can reduce the need for labeled data when deploying models in new buildings, using adversarial training or self-supervised learning to leverage unlabeled data from target domains for model adjustment, reducing deployment costs and labeling workload. Meta-learning methods can learn how to quickly adapt to new tasks from multiple source tasks, achieving rapid personalization under few-shot conditions, which is valuable for rapid deployment to new users. At the task definition level, paradigm shift from continuous power prediction to discrete event detection can be explored: current methods predict power values at each time point, with large amounts of prediction occurring during OFF periods for sparse devices, and this representation may not be optimal; event-driven disaggregation strategies directly detect device ON and OFF events, combined with within-event power estimation, potentially better suited for handling sparse devices and avoiding ineffective prediction during large amounts of OFF periods.

In the application extension direction, this thesis method can extend to broader scenarios and deeper applications. Regarding device type coverage, expansion to emerging load disaggregation is possible: electric vehicle charging has high-power, long-duration, and schedulable characteristics, with accurate identification crucial for smart charging scheduling and grid demand response; air source heat pumps and ground source heat pumps are primary building loads during heating seasons, with operating pattern monitoring important for building energy efficiency assessment; power flow monitoring of photovoltaic inverters and energy storage systems is fundamental for prosumer energy management. Regarding building type extension, exploration from residential to commercial buildings and industrial scenarios is possible; these scenarios have richer device types, larger power magnitudes, and more complex electricity usage patterns, posing higher requirements for disaggregation algorithm scalability and robustness while also containing greater energy-saving potential and economic value. Regarding application depth, NILM can be deeply integrated with other smart technologies: combination with anomaly detection techniques can achieve early warning of device failures, alerting before complete device failure by identifying abnormal power patterns; integration with demand response systems can achieve intelligent scheduling based on load composition, automatically adjusting deferrable loads during peak electricity prices or grid stress periods; fusion with energy management systems can provide more refined energy consumption analysis and energy-saving recommendations, helping users understand and optimize electricity usage behavior.

The development of non-intrusive load monitoring technology is closely related to smart grid construction, building energy conservation and emission reduction, and achievement of dual carbon goals. The CondiNILMformer method proposed in this thesis has achieved significant progress at the technical level, but considerable distance remains from laboratory research to large-scale practical application. It is hoped that the research outcomes and methodological framework of this thesis can provide useful reference for subsequent research in this field, promoting continuous progress in NILM technology regarding data quality improvement, algorithm capability enhancement, and deployment cost reduction, ultimately achieving widespread application in smart grids and smart buildings, contributing technological strength to energy transition and sustainable development.

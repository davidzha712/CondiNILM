#################################################################################################################
#
# Analyze appliance-level electrical statistics over UKDALE (or cached NILM data)
#
#################################################################################################################

import argparse
import logging
import os
import sys
from typing import Dict, Any

import numpy as np
import torch
import yaml
from omegaconf import OmegaConf

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from src.helpers.preprocessing import UKDALE_DataBuilder


def compute_appliance_stats_from_array(power: np.ndarray, status: np.ndarray) -> Dict[str, Any]:
    """
    è®¡ç®—è®¾å¤‡çš„ç”µæ°”ç»Ÿè®¡ç‰¹æ€§ï¼Œç”¨äºè¯†åˆ«ä¸åŒç±»å‹çš„è®¾å¤‡ï¼š
    
    è®¾å¤‡ç±»å‹åˆ†ç±»ï¼š
    1. é¢‘ç¹å¼€å…³è®¾å¤‡ï¼ˆå¦‚Fridgeï¼‰ï¼šduty_cycle ~50%, ä¸­ç­‰åŠŸç‡ï¼Œé¢‘ç¹åˆ‡æ¢
    2. ç¨€ç–é«˜åŠŸç‡è®¾å¤‡ï¼ˆå¦‚Kettle, Microwaveï¼‰ï¼šduty_cycle <5%, é«˜å³°å€¼åŠŸç‡ï¼ŒçŸ­æ—¶ä½¿ç”¨
    3. é•¿æ—¶é—´è¿è¡Œè®¾å¤‡ï¼ˆå¦‚WashingMachineï¼‰ï¼šduty_cycleä¸­ç­‰ï¼ŒåŠŸç‡å˜åŒ–å¤§ï¼Œè¿è¡Œå‘¨æœŸé•¿
    4. å¸¸å¼€è®¾å¤‡ï¼šduty_cycle >80%, åŠŸç‡ç¨³å®š
    """
    power_flat = power.reshape(-1).astype(np.float64)
    status_flat = status.reshape(-1).astype(np.float64) > 0.5
    mask_valid = ~np.isnan(power_flat)
    power_flat = power_flat[mask_valid]
    status_flat = status_flat[mask_valid]
    if power_flat.size == 0:
        return {}
    
    duty = float(status_flat.mean())
    on_mask = status_flat
    off_mask = ~status_flat
    
    # åŸºç¡€ç»Ÿè®¡
    if on_mask.any():
        on_values = power_flat[on_mask]
        peak = float(on_values.max())
        p95_on = float(np.quantile(on_values, 0.95))
        mean_on = float(on_values.mean())
        p05_on = float(np.quantile(on_values, 0.05))
        std_on = float(on_values.std())
    else:
        peak = 0.0
        p95_on = 0.0
        mean_on = 0.0
        p05_on = 0.0
        std_on = 0.0
    
    mean_all = float(power_flat.mean())
    std_all = float(power_flat.std())
    
    # ============== æ–°å¢ï¼šé«˜çº§ç»Ÿè®¡é‡ ==============
    
    # 1. å³°å€¼åŠŸç‡æ¯”ï¼ˆè¯†åˆ«é«˜åŠŸç‡è®¾å¤‡ï¼‰
    peak_to_mean_ratio = peak / (mean_on + 1e-6) if mean_on > 0 else 0.0
    
    # 2. åŠŸç‡å˜åŒ–ç‡ï¼ˆæ£€æµ‹ç¬é—´é«˜åŠŸç‡è®¾å¤‡ï¼‰
    if power_flat.size > 1:
        power_diff = np.abs(np.diff(power_flat))
        max_power_change = float(power_diff.max())
        mean_power_change = float(power_diff.mean())
        p99_power_change = float(np.quantile(power_diff, 0.99))
    else:
        max_power_change = 0.0
        mean_power_change = 0.0
        p99_power_change = 0.0
    
    # 3. ONäº‹ä»¶ç»Ÿè®¡ï¼ˆæ£€æµ‹ä½¿ç”¨æ¨¡å¼ï¼‰
    status_diff = np.diff(status_flat.astype(int))
    on_starts = np.where(status_diff == 1)[0]
    on_ends = np.where(status_diff == -1)[0]
    
    # å¤„ç†è¾¹ç•Œæƒ…å†µ
    if status_flat[0]:
        on_starts = np.concatenate([[0], on_starts])
    if status_flat[-1] and len(on_ends) < len(on_starts):
        on_ends = np.concatenate([on_ends, [len(status_flat) - 1]])
    
    n_events = min(len(on_starts), len(on_ends))
    if n_events > 0:
        event_durations = on_ends[:n_events] - on_starts[:n_events]
        mean_event_duration = float(event_durations.mean())
        median_event_duration = float(np.median(event_durations))
        max_event_duration = float(event_durations.max())
        min_event_duration = float(event_durations.min())
        n_on_events = n_events
    else:
        mean_event_duration = 0.0
        median_event_duration = 0.0
        max_event_duration = 0.0
        min_event_duration = 0.0
        n_on_events = 0
    
    # 4. åŠŸç‡ç¨³å®šæ€§ï¼ˆONæ—¶çš„å˜å¼‚ç³»æ•°ï¼‰
    cv_on = std_on / (mean_on + 1e-6) if mean_on > 0 else 0.0
    
    # 5. ç¨€ç–æ€§æŒ‡æ ‡ï¼ˆè¯†åˆ«ç¨€ç–ä½†é«˜åŠŸç‡çš„è®¾å¤‡ï¼‰
    # æ—¶é—´å¹³å‡åŠŸç‡ vs ONæ—¶å¹³å‡åŠŸç‡çš„æ¯”å€¼
    sparsity_ratio = mean_all / (mean_on + 1e-6) if mean_on > 0 else 0.0
    
    # 6. ç¬æ—¶åŠŸç‡å¯†åº¦ï¼ˆé«˜åŠŸç‡çŸ­æ—¶è®¾å¤‡çš„ç‰¹å¾ï¼‰
    # å³°å€¼åŠŸç‡ Ã— duty_cycle
    power_density = peak * duty
    
    # ============== è®¾å¤‡ç±»å‹åˆ†ç±» ==============
    device_type = classify_device_type(
        duty_cycle=duty,
        peak_power=peak,
        mean_on_power=mean_on,
        cv_on=cv_on,
        mean_event_duration=mean_event_duration,
        n_on_events=n_on_events,
        total_samples=len(power_flat),
    )
    
    return {
        # åŸºç¡€ç»Ÿè®¡
        "duty_cycle": duty,
        "peak_power": peak,
        "p95_on_power": p95_on,
        "p05_on_power": p05_on,
        "mean_on_power": mean_on,
        "std_on_power": std_on,
        "mean_all_power": mean_all,
        "std_all_power": std_all,
        # é«˜çº§ç»Ÿè®¡
        "peak_to_mean_ratio": peak_to_mean_ratio,
        "max_power_change": max_power_change,
        "mean_power_change": mean_power_change,
        "p99_power_change": p99_power_change,
        "cv_on": cv_on,  # å˜å¼‚ç³»æ•°
        "sparsity_ratio": sparsity_ratio,
        "power_density": power_density,
        # ONäº‹ä»¶ç»Ÿè®¡
        "n_on_events": n_on_events,
        "mean_event_duration": mean_event_duration,
        "median_event_duration": median_event_duration,
        "max_event_duration": max_event_duration,
        "min_event_duration": min_event_duration,
        # è®¾å¤‡ç±»å‹åˆ†ç±»
        "device_type": device_type,
    }


def classify_device_type(
    duty_cycle: float,
    peak_power: float,
    mean_on_power: float,
    cv_on: float,
    mean_event_duration: float,
    n_on_events: int,
    total_samples: int,
) -> str:
    """
    æ ¹æ®ç»Ÿè®¡ç‰¹æ€§åˆ†ç±»è®¾å¤‡ç±»å‹ï¼Œç”¨äºè‡ªåŠ¨è°ƒæ•´æŸå¤±å‡½æ•°å‚æ•°ã€‚
    
    Returns:
        è®¾å¤‡ç±»å‹å­—ç¬¦ä¸²ï¼š
        - "sparse_high_power": ç¨€ç–é«˜åŠŸç‡è®¾å¤‡ï¼ˆå¦‚Kettle, Microwaveï¼‰
        - "frequent_switching": é¢‘ç¹å¼€å…³è®¾å¤‡ï¼ˆå¦‚Fridgeï¼‰
        - "long_cycle": é•¿å‘¨æœŸè¿è¡Œè®¾å¤‡ï¼ˆå¦‚WashingMachine, Dishwasherï¼‰
        - "always_on": å¸¸å¼€è®¾å¤‡
        - "low_power": ä½åŠŸç‡è®¾å¤‡
        - "unknown": æ— æ³•åˆ†ç±»
    """
    # äº‹ä»¶é¢‘ç‡ï¼ˆæ¯1000ä¸ªæ ·æœ¬çš„ONäº‹ä»¶æ•°ï¼‰
    event_rate = n_on_events / (total_samples / 1000 + 1e-6) if total_samples > 0 else 0
    
    # 1. ç¨€ç–é«˜åŠŸç‡è®¾å¤‡ï¼šduty_cycleä½ï¼Œå³°å€¼åŠŸç‡é«˜
    if duty_cycle < 0.05 and peak_power > 1000:
        return "sparse_high_power"
    
    # 2. é¢‘ç¹å¼€å…³è®¾å¤‡ï¼šduty_cycleä¸­ç­‰ï¼Œäº‹ä»¶é¢‘ç‡é«˜
    if 0.3 <= duty_cycle <= 0.7 and event_rate > 5:
        return "frequent_switching"
    
    # 3. é•¿å‘¨æœŸè¿è¡Œè®¾å¤‡ï¼šduty_cycleä¸­ç­‰ï¼Œäº‹ä»¶æ—¶é•¿é•¿ï¼ŒåŠŸç‡å˜åŒ–å¤§
    if 0.05 <= duty_cycle <= 0.5 and mean_event_duration > 30 and cv_on > 0.3:
        return "long_cycle"
    
    # 4. å¸¸å¼€è®¾å¤‡ï¼šduty_cycleå¾ˆé«˜
    if duty_cycle > 0.8:
        return "always_on"
    
    # 5. ä½åŠŸç‡è®¾å¤‡ï¼šå³°å€¼åŠŸç‡ä½
    if peak_power < 100:
        return "low_power"
    
    # 6. ç¨€ç–ä¸­ç­‰åŠŸç‡ï¼ˆä»‹äºç¨€ç–é«˜åŠŸç‡å’Œé¢‘ç¹å¼€å…³ä¹‹é—´ï¼‰
    if duty_cycle < 0.15 and peak_power > 200:
        return "sparse_medium_power"
    
    return "unknown"


def get_recommended_loss_params(device_type: str, stats: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ ¹æ®è®¾å¤‡ç±»å‹è¿”å›æ¨èçš„æŸå¤±å‡½æ•°å‚æ•°ã€‚
    """
    duty = stats.get("duty_cycle", 0.5)
    peak = stats.get("peak_power", 100)
    
    if device_type == "sparse_high_power":
        # ç¨€ç–é«˜åŠŸç‡è®¾å¤‡ï¼ˆå¦‚Kettle, Microwaveï¼‰
        # ç‰¹ç‚¹ï¼šONäº‹ä»¶ç¨€å°‘ä½†åŠŸç‡å¾ˆé«˜ï¼Œéœ€è¦å¼ºè°ƒONäº‹ä»¶çš„å‡†ç¡®æ•è·
        return {
            "alpha_on": 8.0,      # æé«˜ONæƒé‡ï¼Œå› ä¸ºONå¾ˆç¨€å°‘
            "alpha_off": 0.3,     # ä½OFFæƒé‡
            "lambda_zero": 0.8,   # é«˜OFFæƒ©ç½š
            "lambda_off_hard": 1.5,  # å¼ºOFFçº¦æŸ
            "lambda_gate_cls": 0.8,  # é«˜é—¨æ§åˆ†ç±»æƒé‡
            "lambda_energy": 0.05,   # ä½èƒ½é‡çº¦æŸï¼ˆå› ä¸ºæ€»èƒ½é‡ä½ï¼‰
            "description": "ç¨€ç–é«˜åŠŸç‡è®¾å¤‡ï¼šå¼ºè°ƒONäº‹ä»¶æ£€æµ‹ï¼Œä¸¥æ ¼OFFçº¦æŸ",
        }
    
    elif device_type == "frequent_switching":
        # é¢‘ç¹å¼€å…³è®¾å¤‡ï¼ˆå¦‚Fridgeï¼‰
        # ç‰¹ç‚¹ï¼šON/OFFå„çº¦50%ï¼Œé¢‘ç¹åˆ‡æ¢
        return {
            "alpha_on": 1.5,
            "alpha_off": 1.2,
            "lambda_zero": 0.5,
            "lambda_off_hard": 1.2,
            "lambda_gate_cls": 0.5,
            "lambda_energy": 0.25,
            "description": "é¢‘ç¹å¼€å…³è®¾å¤‡ï¼šå¹³è¡¡ON/OFFæƒé‡ï¼Œå¼ºåŒ–çŠ¶æ€åˆ‡æ¢å­¦ä¹ ",
        }
    
    elif device_type == "long_cycle":
        # é•¿å‘¨æœŸè¿è¡Œè®¾å¤‡ï¼ˆå¦‚WashingMachine, Dishwasherï¼‰
        # ç‰¹ç‚¹ï¼šè¿è¡Œå‘¨æœŸé•¿ï¼ŒåŠŸç‡å˜åŒ–å¤§
        return {
            "alpha_on": 3.0,
            "alpha_off": 1.0,
            "lambda_zero": 0.3,
            "lambda_off_hard": 0.5,
            "lambda_gate_cls": 0.3,
            "lambda_energy": 0.15,
            "description": "é•¿å‘¨æœŸè®¾å¤‡ï¼šä¸­ç­‰æƒé‡å¹³è¡¡ï¼Œå…³æ³¨åŠŸç‡å˜åŒ–è¶‹åŠ¿",
        }
    
    elif device_type == "always_on":
        # å¸¸å¼€è®¾å¤‡
        return {
            "alpha_on": 1.0,
            "alpha_off": 3.0,
            "lambda_zero": 0.1,
            "lambda_off_hard": 0.2,
            "lambda_gate_cls": 0.1,
            "lambda_energy": 0.3,
            "description": "å¸¸å¼€è®¾å¤‡ï¼šå¼ºè°ƒOFFäº‹ä»¶æ£€æµ‹ï¼ˆå¼‚å¸¸æ£€æµ‹ï¼‰",
        }
    
    elif device_type == "sparse_medium_power":
        # ç¨€ç–ä¸­ç­‰åŠŸç‡
        return {
            "alpha_on": 5.0,
            "alpha_off": 0.8,
            "lambda_zero": 0.6,
            "lambda_off_hard": 1.0,
            "lambda_gate_cls": 0.5,
            "lambda_energy": 0.08,
            "description": "ç¨€ç–ä¸­ç­‰åŠŸç‡è®¾å¤‡",
        }
    
    else:
        # é»˜è®¤å‚æ•°
        return {
            "alpha_on": 3.0,
            "alpha_off": 1.0,
            "lambda_zero": 0.3,
            "lambda_off_hard": 0.5,
            "lambda_gate_cls": 0.3,
            "lambda_energy": 0.1,
            "description": "é»˜è®¤å‚æ•°",
        }


def analyze_ukdale_appliance(dataset_root: str, appliance: str, sampling_rate: str, window_size: int, seed: int = 42):
    base_expes = {}
    with open("configs/datasets.yaml", "r") as f:
        datasets_all = yaml.safe_load(f)
        if "UKDALE" in datasets_all and appliance in datasets_all["UKDALE"]:
            base_expes.update(datasets_all["UKDALE"][appliance])
    with open("configs/expes.yaml", "r") as f:
        expes_yaml = yaml.safe_load(f)
        base_expes.update(expes_yaml)
    base_expes["dataset"] = "UKDALE"
    base_expes["appliance"] = appliance
    base_expes["sampling_rate"] = sampling_rate
    base_expes["window_size"] = window_size
    base_expes["seed"] = seed
    base_expes["name_model"] = "NILMFormer"
    base_expes = OmegaConf.create(base_expes)
    app_internal = getattr(base_expes, "app", appliance)

    data_path = os.path.join(dataset_root, "UKDALE")
    data_builder = UKDALE_DataBuilder(
        data_path=data_path,
        mask_app=app_internal,
        sampling_rate=sampling_rate,
        window_size=window_size,
    )
    houses = []
    if "ind_house_train_val" in base_expes:
        houses.extend(list(base_expes.ind_house_train_val))
    if "ind_house_test" in base_expes:
        houses.extend(list(base_expes.ind_house_test))
    if not houses:
        houses = [1, 2, 3, 4, 5]
    houses = sorted(set(int(h) for h in houses))
    data, st_date = data_builder.get_nilm_dataset(house_indicies=houses)
    power = data[:, 1, 0, :]
    status = data[:, 1, 1, :]
    stats = compute_appliance_stats_from_array(power, status)
    stats["kelly_min_threshold_watts"] = float(
        data_builder.appliance_param[app_internal]["min_threshold"]
    )
    return stats


def main():
    parser = argparse.ArgumentParser(
        description="Analyze appliance-level statistics over UKDALE or cached NILM data."
    )
    parser.add_argument(
        "--sampling_rate",
        type=str,
        default="1min",
        help="Sampling rate, e.g. '1min'.",
    )
    parser.add_argument(
        "--window_size",
        type=int,
        default=256,
        help="Window size used for NILM preprocessing.",
    )
    parser.add_argument(
        "--dataset_root",
        type=str,
        default="data",
        help="Root directory for raw datasets (containing UKDALE/).",
    )
    parser.add_argument(
        "--appliances",
        type=str,
        default="all",
        help="Comma-separated list of appliances to analyze or 'all' for all UKDALE appliances.",
    )
    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO)

    with open("configs/datasets.yaml", "r") as f:
        datasets_all = yaml.safe_load(f)
    if "UKDALE" not in datasets_all:
        raise ValueError("UKDALE dataset configuration not found in configs/datasets.yaml")
    all_appliances = list(datasets_all["UKDALE"].keys())

    if args.appliances == "all":
        target_appliances = all_appliances
    else:
        names = [x.strip() for x in args.appliances.split(",") if x.strip()]
        target_appliances = [x for x in names if x in all_appliances]
        if not target_appliances:
            raise ValueError(f"No valid appliances from {names}, available: {all_appliances}")

    result = {}
    for app in target_appliances:
        logging.info("Analyze appliance %s", app)
        stats = analyze_ukdale_appliance(
            dataset_root=args.dataset_root,
            appliance=app,
            sampling_rate=args.sampling_rate,
            window_size=int(args.window_size),
        )
        result[app] = stats

    print("\n" + "=" * 80)
    print("Appliance Statistics Analysis (UKDALE)")
    print("=" * 80)
    
    for app, stats in result.items():
        if not stats:
            continue
        device_type = stats.get("device_type", "unknown")
        print(f"\n{'â”€' * 40}")
        print(f"ğŸ“Š {app} [{device_type}]")
        print(f"{'â”€' * 40}")
        
        # æ ¸å¿ƒæŒ‡æ ‡
        print(f"  Duty Cycle:        {stats.get('duty_cycle', 0):.2%}")
        print(f"  Peak Power:        {stats.get('peak_power', 0):.1f} W")
        print(f"  Mean ON Power:     {stats.get('mean_on_power', 0):.1f} W")
        print(f"  Mean ALL Power:    {stats.get('mean_all_power', 0):.1f} W")
        
        # ONäº‹ä»¶ç»Ÿè®¡
        print(f"\n  ON Event Stats:")
        print(f"    Number of events:    {stats.get('n_on_events', 0)}")
        print(f"    Mean duration:       {stats.get('mean_event_duration', 0):.1f} samples")
        print(f"    Median duration:     {stats.get('median_event_duration', 0):.1f} samples")
        
        # åŠŸç‡ç‰¹æ€§
        print(f"\n  Power Characteristics:")
        print(f"    Peak/Mean ratio:     {stats.get('peak_to_mean_ratio', 0):.2f}")
        print(f"    CV (ON):             {stats.get('cv_on', 0):.3f}")
        print(f"    Max power change:    {stats.get('max_power_change', 0):.1f} W")
        print(f"    Sparsity ratio:      {stats.get('sparsity_ratio', 0):.3f}")
        
        # æ¨èå‚æ•°
        recommended = get_recommended_loss_params(device_type, stats)
        print(f"\n  ğŸ“‹ Recommended Loss Parameters:")
        print(f"    Description: {recommended.get('description', '')}")
        print(f"    alpha_on:           {recommended.get('alpha_on', 3.0)}")
        print(f"    alpha_off:          {recommended.get('alpha_off', 1.0)}")
        print(f"    lambda_zero:        {recommended.get('lambda_zero', 0.3)}")
        print(f"    lambda_off_hard:    {recommended.get('lambda_off_hard', 0.5)}")
        print(f"    lambda_gate_cls:    {recommended.get('lambda_gate_cls', 0.3)}")
        print(f"    lambda_energy:      {recommended.get('lambda_energy', 0.1)}")
    
    print(f"\n{'=' * 80}")
    print("Legend:")
    print("  - sparse_high_power:    ç¨€ç–é«˜åŠŸç‡è®¾å¤‡ï¼ˆå¦‚Kettle, Microwaveï¼‰")
    print("  - frequent_switching:   é¢‘ç¹å¼€å…³è®¾å¤‡ï¼ˆå¦‚Fridgeï¼‰")
    print("  - long_cycle:           é•¿å‘¨æœŸè¿è¡Œè®¾å¤‡ï¼ˆå¦‚WashingMachineï¼‰")
    print("  - always_on:            å¸¸å¼€è®¾å¤‡")
    print("  - sparse_medium_power:  ç¨€ç–ä¸­ç­‰åŠŸç‡è®¾å¤‡")
    print("=" * 80)


if __name__ == "__main__":
    main()

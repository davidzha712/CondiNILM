\section{Ablation Studies}
\label{sec:ablation}

This section isolates the contribution of each architectural component in CondiNILMformer through systematic ablation experiments. All ablation variants are trained and evaluated under the UK-DALE five-device joint-training setting to ensure consistency with the multi-device results reported in Section~\ref{subsec:multi_device}.

\subsection{Ablation Configuration}
\label{subsec:ablation_config}

Nine model configurations are compared: the full CondiNILMformer and eight ablation variants, each removing or modifying one component while keeping the remaining setup unchanged. The variants are defined as follows:

\begin{itemize}
    \item \textbf{A1: w/o FiLM} --- Remove all FiLM conditioning layers, eliminating both electrical and frequency-domain feature injection.
    \item \textbf{A2: w/o AdaptiveLoss} --- Replace AdaptiveDeviceLoss with standard SmoothL1 loss applied uniformly across all devices.
    \item \textbf{A3: w/o Seq2SubSeq} --- Replace centre-region supervision with full-sequence supervision, removing the boundary-artefact reduction mechanism.
    \item \textbf{A4: w/o Soft Gate} --- Remove the per-device learnable soft gating mechanism that separates energy estimation from state detection.
    \item \textbf{A5: w/o PCGrad} --- Disable PCGrad gradient conflict resolution in shared-parameter updates, allowing unmitigated gradient conflicts during multi-device optimisation.
    \item \textbf{A6: Elec FiLM Only} --- Retain only electrical-domain FiLM conditioning, removing frequency-domain modulation.
    \item \textbf{A7: Freq FiLM Only} --- Retain only frequency-domain FiLM conditioning, removing electrical-domain modulation.
    \item \textbf{A8: Vanilla Backbone} --- Remove all CondiNILMformer-specific components (FiLM, adapters, type-grouped heads, AdaptiveDeviceLoss, PCGrad), reducing the architecture to a vanilla Transformer backbone.
\end{itemize}

\subsection{Ablation Results}
\label{subsec:ablation_results}

Table~\ref{tab:ablation} summarises the ablation results across eight evaluation metrics. The variants are ordered by NDE to highlight the disaggregation quality gradient.

\begin{table}[htbp]
\centering
\caption{Ablation study results on UK-DALE multi-device joint training. Variants are ordered by NDE (lower is better). ``---'' indicates training collapse where the model failed to produce meaningful predictions. Best results per metric are shown in bold.}
\label{tab:ablation}
\resizebox{\textwidth}{!}{%
\begin{tabular}{l c c c c c c c c}
\toprule
\textbf{Variant} & \textbf{MAE}$\downarrow$ & \textbf{NDE}$\downarrow$ & \textbf{SAE}$\downarrow$ & \textbf{TECA}$\uparrow$ & \textbf{MR}$\downarrow$ & \textbf{F1}$\uparrow$ & \textbf{Prec}$\uparrow$ & \textbf{Rec}$\uparrow$ \\
\midrule
A7: Freq FiLM only & 21.2 & \textbf{0.372} & \textbf{0.401} & 0.581 & \textbf{0.483} & \textbf{0.712} & 0.568 & \textbf{0.955} \\
\textbf{CondiNILMformer (full)} & \textbf{20.4} & 0.398 & 0.552 & \textbf{0.589} & 0.513 & 0.639 & 0.496 & 0.899 \\
A4: w/o Soft Gate & 20.4 & 0.571 & 0.242 & 0.597 & 0.471 & 0.777 & \textbf{0.661} & 0.941 \\
A3: w/o Seq2SubSeq & \textbf{18.3} & 0.688 & \textbf{0.094} & 0.638 & 0.450 & 0.762 & 0.656 & 0.910 \\
A6: Elec FiLM only & 21.0 & 0.730 & 0.146 & 0.586 & 0.443 & 0.779 & 0.672 & 0.926 \\
A1: w/o FiLM & 23.5 & 0.899 & 0.141 & 0.537 & 0.396 & 0.764 & 0.651 & 0.924 \\
\midrule
A2: w/o AdaptiveLoss & 25.3 & --- & 1.000 & 0.500 & 0.000 & 0.000 & 0.000 & 0.000 \\
A5: w/o PCGrad & 25.3 & --- & 1.000 & 0.500 & 0.000 & 0.000 & 0.000 & 0.000 \\
A8: Vanilla backbone & 25.3 & --- & 1.000 & 0.500 & 0.000 & 0.000 & 0.000 & 0.000 \\
\bottomrule
\end{tabular}
}
\end{table}

\subsection{Analysis of Component Contributions}
\label{subsec:ablation_analysis}

The ablation results show a multi-objective trade-off surface rather than a single monotonic ranking. Different variants dominate different metrics, so component importance must be interpreted in terms of \textit{stability-oriented Pareto trade-offs}.

\subsubsection{Stability-Critical (Seed-42): AdaptiveDeviceLoss and PCGrad}

The most striking finding is that, under the current UK-DALE five-device joint-training setting (seed 42), removing either AdaptiveDeviceLoss (A2) or PCGrad (A5) causes \textit{complete training collapse}, with F1 dropping to 0.000 and SAE reaching 1.000. The vanilla backbone variant (A8), which removes all proposed components simultaneously, exhibits the same collapse. This indicates that these two components are \textit{stability-critical under seed-42} rather than universally required in all settings. Without AdaptiveDeviceLoss, the uniform loss function fails to account for the vastly different power scales and activation frequencies across devices, causing the optimiser to converge to a trivial solution. Without PCGrad, unmitigated gradient conflicts between device-specific objectives prevent meaningful learning, as gradient updates for one device systematically undo progress on others. Establishing broader necessity beyond this setting requires multi-seed and cross-split validation.

\subsubsection{Critical Component: FiLM Conditioning}

FiLM conditioning is the most important component for disaggregation quality among the non-collapse variants. Complete removal of FiLM (A1) degrades NDE from 0.398 to 0.899, representing a 126\% increase. The comparison between single-domain variants is informative: frequency-domain FiLM alone (A7, NDE = 0.372) outperforms electrical-domain FiLM alone (A6, NDE = 0.730) by a substantial margin. This suggests that frequency-domain features---which capture periodicity and harmonic signatures---are highly discriminative for device identification. Notably, the frequency-only variant achieves the best NDE (0.372), while the full model maintains better collapse resistance and a broader multi-metric balance under the selected deployment objective.

\subsubsection{Supporting Components: Soft Gate and Seq2SubSeq}

The soft gating mechanism mainly improves NDE-oriented energy disaggregation. Its removal (A4) increases NDE from 0.398 to 0.571, a 43\% degradation. However, A4 also yields higher F1 and Precision than the full model, showing that gating shifts the operating point toward better energy consistency at the cost of some classification sharpness. Therefore, soft gating should be interpreted as a metric-trade-off module rather than a uniformly improving component.

Seq2SubSeq centre supervision (A3) primarily affects NDE stability. Its removal increases NDE from 0.398 to 0.688 (+73\%), indicating that centre-region supervision reduces boundary artefacts that arise when the model attempts to predict precise activation edges. At the same time, A3 achieves the lowest MAE (18.3~W) and SAE (0.094) among non-collapsed variants, confirming a clear trade-off between boundary-stable disaggregation (favoured by centre supervision) and average-error minimisation (favoured by full-sequence supervision).

\subsection{Component Synergy Analysis}
\label{subsec:interactions}

The ablation results reveal important synergistic interactions between components. Although the frequency-only FiLM variant achieves the lowest NDE (0.372), the full model is selected as a stability-oriented operating point that jointly considers collapse resistance, TECA behaviour, and acceptable NDE under multi-device training. Thus, the chosen configuration is not uniformly best on every metric, but a pragmatic Pareto compromise for deployment.

A particularly instructive comparison involves the A4 (w/o Soft Gate) and A1 (w/o FiLM) variants. Although removing the soft gate has a smaller isolated impact on NDE (+43\%) than removing FiLM (+126\%), the gate mechanism is necessary for FiLM conditioning to achieve its full potential. FiLM provides device-aware feature modulation, but without gating, the model cannot effectively translate these modulated features into separate energy and state predictions.

The seed-42 stability-critical role of AdaptiveDeviceLoss and PCGrad further underscores this systems-level perspective. Even a strong feature representation (FiLM + soft gate + Seq2SubSeq) can fail without appropriate loss design and gradient management in this setting. For stability-oriented deployment goals, retaining the complete component stack is therefore recommended; generality of this recommendation should be validated with multi-seed evidence.
